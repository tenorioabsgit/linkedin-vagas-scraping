# ğŸ“Œ Carregar bibliotecas necessÃ¡rias
library(chromote)
library(rvest)
library(dplyr)
library(stringr)
library(tidyverse)
library(parsedate)
library(gmailr)
library(knitr)
library(kableExtra)

# ğŸ“Œ Criar uma nova sessÃ£o do Chromote
b <- ChromoteSession$new()

# ğŸ“Œ FunÃ§Ã£o para capturar vagas no LinkedIn com filtro de perÃ­odo e descriÃ§Ã£o da vaga
scrape_linkedin_jobs <- function(keyword, pages = 3, periodo = "r5184000") {  # ğŸ”¹ Ãšltimos 60 dias (60 dias * 86400 seg)
  base_url <- "https://www.linkedin.com/jobs/search/?"
  query <- paste0("keywords=", URLencode(keyword), 
                  "&location=Brazil", 
                  "&f_TPR=", periodo)  # ğŸ”¹ Adicionando filtro de perÃ­odo na URL
  full_url <- paste0(base_url, query)
  
  b$Page$navigate(full_url)
  Sys.sleep(5)  # Tempo para carregar a pÃ¡gina
  
  job_list <- list()
  
  for (i in 1:pages) {
    page_source <- b$Runtime$evaluate("document.documentElement.outerHTML")$result$value
    html <- read_html(page_source)
    
    titles <- html %>% html_nodes(".base-search-card__title") %>% html_text(trim = TRUE)
    companies <- html %>% html_nodes(".base-search-card__subtitle") %>% html_text(trim = TRUE)
    locations <- html %>% html_nodes(".job-search-card__location") %>% html_text(trim = TRUE)
    links <- html %>% html_nodes(".base-card__full-link") %>% html_attr("href")
    dates <- html %>% html_nodes(".job-search-card__listdate") %>% html_text(trim = TRUE)
    
    # Converter texto das datas para formato legÃ­vel
    dates <- dates %>%
      str_replace_all("hÃ¡ ", "") %>%
      str_replace_all("dia", "dias") %>%
      str_replace_all("um", "1") %>%
      str_extract("\\d+") %>%
      as.numeric() %>%
      replace_na(0) %>%
      {Sys.Date() - .}  # ğŸ”¹ Subtrai os dias para estimar a data real da postagem
    
    # ğŸ”¹ Coletar descriÃ§Ã£o de cada vaga
    descriptions <- map_chr(links, function(url) {
      if (!is.na(url)) {
        b$Page$navigate(url)
        Sys.sleep(3)  # Esperar carregamento
        page_source <- b$Runtime$evaluate("document.documentElement.outerHTML")$result$value
        job_html <- read_html(page_source)
        
        # Extrair descriÃ§Ã£o da vaga
        job_html %>%
          html_nodes(".description__text") %>%
          html_text(trim = TRUE) %>%
          paste(collapse = " ")  # Concatenar caso haja mÃºltiplos elementos
      } else {
        NA
      }
    })
    
    # Garantindo que as listas tenham o mesmo comprimento
    max_length <- max(length(titles), length(companies), length(locations), length(links), length(dates), length(descriptions))
    titles <- c(titles, rep(NA, max_length - length(titles)))
    companies <- c(companies, rep(NA, max_length - length(companies)))
    locations <- c(locations, rep(NA, max_length - length(locations)))
    links <- c(links, rep(NA, max_length - length(links)))
    dates <- c(dates, rep(NA, max_length - length(dates)))
    descriptions <- c(descriptions, rep(NA, max_length - length(descriptions)))
    
    # Criar dataframe e adicionar Ã  lista
    job_data <- tibble(
      Titulo = titles,
      Empresa = companies,
      Localizacao = locations,
      Link = links,
      Data_Publicacao = dates,
      Descricao = descriptions
    )
    
    job_list <- append(job_list, list(job_data))
    
    # Verificar botÃ£o de "PrÃ³xima PÃ¡gina"
    next_button <- html %>% html_nodes(".artdeco-pagination__button--next")
    if (length(next_button) == 0) break
    
    Sys.sleep(5)  # Pausa antes de carregar a prÃ³xima pÃ¡gina
  }
  
  return(bind_rows(job_list))
}

# ğŸ“Œ Lista de palavras-chave para busca
keywords <- c("Data Scientist", "Data Science", "CiÃªncia de Dados", 
              "Data Engineering", "Engenharia de Dados", "Engenheiro de Dados")

# ğŸ“Œ Coletar vagas para cada palavra-chave (Ãšltimos 60 dias)
vagas_total <- map_dfr(keywords, ~scrape_linkedin_jobs(.x, pages = 3, periodo = "r5184000"))

# ğŸ“Œ Fechar sessÃ£o Chromote
b$close()

# ================================================================
# ğŸ”¹ 2. Criar coluna Dummy para vagas remotas (1 = remoto, 0 = hÃ­brido/presencial)
# ================================================================

print("ğŸ” Vagas extraÃ­das (antes da categorizaÃ§Ã£o de remoto):")
print(vagas_total)

# ğŸ“Œ Lista de palavras-chave para identificar trabalho remoto
termos_remoto <- c("remoto", "home office", "teletrabalho", "trabalho remoto", 
                   "anywhere", "remote", "virtual", "trabalho Ã  distÃ¢ncia", 
                   "full remote", "trabalho distribuÃ­do", "remote work", "work from home", 
                   "fully remote", "remote-first", "remote position", "distributed team", 
                   "work anywhere", "flexible location", "telecommuting", "trabalho de qualquer lugar",
                   "vaga 100% remota", "vaga remota", "trabalho hÃ­brido opcional")

# ğŸ“Œ Criar colunas auxiliares para anÃ¡lise de remoto
vagas_total <- vagas_total %>%
  mutate(
    local_lower = str_to_lower(Localizacao),
    titulo_lower = str_to_lower(Titulo),
    descricao_lower = str_to_lower(Descricao),
    Remoto = ifelse(
      str_detect(local_lower, paste(termos_remoto, collapse = "|")) | 
        str_detect(titulo_lower, paste(termos_remoto, collapse = "|")) |
        str_detect(descricao_lower, paste(termos_remoto, collapse = "|")), 
      1, 0  # ğŸ”¹ 1 = remoto, 0 = hÃ­brido/presencial
    )
  )

# ğŸ“Œ Salvar os resultados em um arquivo CSV
write_csv(vagas_total, "vagas_linkedin.csv")

# ğŸ“Œ Exibir resultado final
print("âœ… Vagas extraÃ­das com classificaÃ§Ã£o de trabalho remoto. Arquivo salvo como 'vagas_linkedin.csv'.")
print(vagas_total)
